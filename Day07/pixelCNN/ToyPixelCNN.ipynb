{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def show_as_image(binary_image, figsize=(10, 5)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(binary_image, cmap='gray')\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pixel CNN\n",
    "\n",
    "Alternative to Pixel RNN from [Pixel Recurrent Neural Networks](https://arxiv.org/pdf/1601.06759.pdf). \n",
    "\n",
    "On-line resources:\n",
    " * See for an existing PyTorch implementation https://github.com/jzbontar/pixelcnn-pytorch/blob/master/main.py\n",
    " * http://sergeiturukin.com/2017/02/22/pixelcnn.html for a nice walk-through\n",
    " * http://tinyclouds.org/residency/\n",
    " * https://tensorflow.blog/2016/11/29/pixelcnn-1601-06759-summary/ (in korean ;) ) \n",
    "\n",
    "The core ideas are the following:\n",
    "\n",
    "### Joint distribution of an image $\\mathbf{x}$ modelled as an autoregressive process\n",
    "\n",
    "Same model for PixelRNN and PixelCNN:\n",
    "\n",
    "$$p(\\mathbf{x}) = \\prod_{i=1}^{n^2} p(x_i|x_{1}, \\dots, x_{i-1})$$\n",
    " \n",
    "![](http://sergeiturukin.com/assets/2017-02-22-183010_479x494_scrot.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 위 사진처럼 생긴 Mask를 생성.\n",
    "이 Mask를 convolution filter적용하면 convolution filter를 causal하게 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  True/False로 구성된 Mask\n",
    "def causal_mask(width, height, starting_point):\n",
    "    row_grid, col_grid = np.meshgrid(np.arange(width), np.arange(height), indexing='ij')\n",
    "#     print(row_grid)\n",
    "#     print()\n",
    "#     print(col_grid)\n",
    "#     print('Mask making')\n",
    "#     print(row_grid<starting_point[0])\n",
    "#     print()\n",
    "#     print(np.logical_and(row_grid == starting_point[0], col_grid <= starting_point[1]))\n",
    "#     print()\n",
    "#     print(np.logical_or(\n",
    "#         row_grid < starting_point[0],\n",
    "#         np.logical_and(row_grid == starting_point[0], col_grid <= starting_point[1])))\n",
    "    mask = np.logical_or(\n",
    "        row_grid < starting_point[0],\n",
    "        np.logical_and(row_grid == starting_point[0], col_grid <= starting_point[1]))\n",
    "    return mask\n",
    "\n",
    "# True/False Mask를 1,0로 구성된 Mask로 단순 변환\n",
    "# B 타입의 경우 include_center=True\n",
    "# A 타입의 경우 include_center=False\n",
    "def conv_mask(width, height, include_center=False):\n",
    "    return 1.0 * causal_mask(width, height, starting_point=(width//2, height//2 + include_center - 1))\n",
    "\n",
    "show_as_image(conv_mask(5, 5, include_center=True))\n",
    "show_as_image(conv_mask(5, 5, include_center=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-ing all inputs weights after center point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_channels, in_channels, width, height = 2, 2, 3, 3\n",
    "\n",
    "conv_weights = 1 + np.arange(out_channels * in_channels * width * height).reshape((out_channels, in_channels, width, height))\n",
    "\n",
    "# conv_weights에 mask를 씌우면 weights 중간을 기준으로 그 전 값들만 통과하고 나머지는 0이 된다.\n",
    "masked_weights = conv_weights * conv_mask(width, height)\n",
    "\n",
    "masked_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 일반적인 convolutional filter(weight)으로 convolution을 하는 것이 아니고,\n",
    "# Causal Mask가 적용된 filter(weight)으로 convolution을 하는 모듈을 생성\n",
    "# (아래 두 그림 참고)\n",
    "class MaskedConv2d(nn.Conv2d):\n",
    "    def __init__(self, mask_type, *args, **kwargs):\n",
    "        super(MaskedConv2d, self).__init__(*args, **kwargs)\n",
    "        _, n_channels, width, height = self.weight.size()\n",
    "\n",
    "        mask = conv_mask(width, height, include_center=mask_type=='B')\n",
    "        self.register_buffer('mask', torch.from_numpy(mask).float())\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.weight.data *= self.mask\n",
    "        return super(MaskedConv2d, self).forward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully convolutional network preserving spatial resolution\n",
    "\n",
    "Input to output map      |  Output distribution\n",
    ":-------------------------:|:-------------------------:\n",
    "![](https://tensorflowkorea.files.wordpress.com/2016/11/pixel-cnn1.png)  |  ![](http://tinyclouds.org/residency/pixelcnn.png)\n",
    "\n",
    "Quite a counter-intuitive model:\n",
    "\n",
    " * Convolutional layers bottom to top!\n",
    " * Last layer with `kernel_size=1` and outputs $ n_W \\times n_H \\times n_{pixels}$ logits, inferring $p(\\mathbf{x})$ in one forward pass (during training)\n",
    " * Representation of dimension `n_channels` output by each layer anologous to RNN's internal state vector $\\mathbf{h}$\n",
    " * Necessary to stack enough layers (and/or dillatations) to augment the \"receptive field\" so that output pixels can be influenced by the whole image\n",
    " \n",
    "\n",
    "Below is a minimalistic implementation for 0/1 pixels without many of the bells and whistles of the original paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PixelCNN(nn.Module):\n",
    "    n_channels = 4\n",
    "    kernel_size = 7\n",
    "    padding = 3\n",
    "    n_pixels_out = 2 # binary 0/1 pixels\n",
    "    \n",
    "    # MaskedConv2d A - BN - ReLU - MaskedConv2d B - BN - ReLU - MaskedConv2d B - BN - ReLU - Conv2d\n",
    "    def __init__(self):\n",
    "        super(PixelCNN, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            MaskedConv2d('A', in_channels=1, out_channels=self.n_channels, kernel_size=self.kernel_size, padding=self.padding, bias=False), nn.BatchNorm2d(self.n_channels), nn.ReLU(True),\n",
    "            MaskedConv2d('B', self.n_channels, self.n_channels, kernel_size=self.kernel_size, padding=self.padding, bias=False), nn.BatchNorm2d(self.n_channels), nn.ReLU(True),\n",
    "            MaskedConv2d('B', self.n_channels, self.n_channels, kernel_size=self.kernel_size, padding=self.padding, bias=False), nn.BatchNorm2d(self.n_channels), nn.ReLU(True),\n",
    "            nn.Conv2d(in_channels=self.n_channels, out_channels=self.n_pixels_out, kernel_size=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        pixel_logits = self.layers(x)\n",
    "        return pixel_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LCD 숫자 이미지를 생성하는 심플한 generative model을 만들어 보자\n",
    "<br>\n",
    "Application on a simple generative model of LCD digits\n",
    "<br>\n",
    "From https://gist.github.com/benjaminwilson/b25a321f292f98d74269b83d4ed2b9a8#file-lcd-digits-dataset-nmf-ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CELL_LENGTH = 4 # 숫자의 한 획의 길이\n",
    "IMAGE_WIDTH, IMAGE_HEIGHT = 2 * CELL_LENGTH + 5, CELL_LENGTH + 4 # 획의 길이에 따른 LCD 이미지 규격\n",
    "\n",
    "# 세로 획 그리기\n",
    "def vertical_stroke(rightness, downness):\n",
    "    \"\"\"\n",
    "    Return a 2d numpy array representing an image with a single vertical stroke in it.\n",
    "    `rightness` and `downness` are values from [0, 1] and define the position of the vertical stroke.\n",
    "    \"\"\"\n",
    "    i = (downness * (CELL_LENGTH + 1)) + 2\n",
    "    j = rightness * (CELL_LENGTH + 1) + 1\n",
    "    x = np.zeros(shape=(IMAGE_WIDTH, IMAGE_HEIGHT), dtype=np.float64)\n",
    "    x[i + np.arange(CELL_LENGTH), j] = 1.\n",
    "    return x\n",
    "\n",
    "# 가로 획 그리기\n",
    "def horizontal_stroke(downness):\n",
    "    \"\"\"\n",
    "    Analogue to vertical_stroke, but it returns horizontal strokes.\n",
    "    `downness` is here a value in [0, 1, 2].\n",
    "    \"\"\"\n",
    "    i = (downness * (CELL_LENGTH + 1)) + 1\n",
    "    x = np.zeros(shape=(IMAGE_WIDTH, IMAGE_HEIGHT), dtype=np.float64)\n",
    "    x[i, 2 + np.arange(CELL_LENGTH)] = 1.\n",
    "    return x\n",
    "\n",
    "show_as_image(horizontal_stroke(0))\n",
    "# show_as_image(horizontal_stroke(1))\n",
    "# show_as_image(horizontal_stroke(2))\n",
    "# show_as_image(vertical_stroke(0,0))\n",
    "# show_as_image(vertical_stroke(0,1))\n",
    "# show_as_image(vertical_stroke(1,0))\n",
    "# show_as_image(vertical_stroke(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 ~ 9 사이의 숫자를 만들 수 있는 기본 획(가로, 세로)들 총 집합.\n",
    "# 가로 획 3개 + 세로 획 4개 = 총 7개 획\n",
    "BASE_STROKES = np.asarray(\n",
    "    [horizontal_stroke(k) for k in range(3)] + [vertical_stroke(k, l) for k in range(2) for l in range(2)])\n",
    "\n",
    "# 기본 획들 총 집합 중에서 각 숫자를 만들기 위해 실제로 필요한 획 구성 \n",
    "DIGITS_STROKES = np.array([[0, 2, 3, 4, 5, 6], [5, 6], [0, 1, 2, 4, 5], [0, 1, 2, 5, 6], [1, 3, 5, 6], [0, 1, 2, 3, 6], [0, 1, 2, 3, 4, 6], [0, 5, 6], np.arange(7), [0, 1, 2, 3, 5, 6]])\n",
    "\n",
    "# 저 기본 획들과 각 숫자를 만들기 위한 조합을 이용해서 랜덤 숫자 이미지를 만들어 낸다.\n",
    "def random_digits(strokes=BASE_STROKES, digit_as_strokes=DIGITS_STROKES, fixed_label=None):\n",
    "    label = fixed_label if fixed_label is not None else np.random.choice(len(digit_as_strokes))\n",
    "    combined_strokes = strokes[digit_as_strokes[label], :, :].sum(axis=0)\n",
    "    return combined_strokes, label\n",
    "\n",
    "def batch_images_to_one(batches_images):\n",
    "    n_square_elements = int(np.sqrt(batches_images.shape[0]))\n",
    "    rows_images = np.split(np.squeeze(batches_images), n_square_elements)\n",
    "    return np.vstack([np.hstack(row_images) for row_images in rows_images])\n",
    "\n",
    "print(random_digits()[0])\n",
    "show_as_image(random_digits()[0])\n",
    "# show_as_image(random_digits()[0])\n",
    "# show_as_image(random_digits()[0])\n",
    "# show_as_image(random_digits(fixed_label=3)[0])\n",
    "# show_as_image(random_digits(fixed_label=4)[0])\n",
    "# show_as_image(random_digits(fixed_label=5)[0])\n",
    "# show_as_image(batch_images_to_one(np.stack([random_digits()[0] for _ in range(25)])), figsize=(9, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 위에서 만든, LCD Digits 만들기 함수를 이용해서 Custom Dataset을 만든다.\n",
    "class LcdDigits(Dataset):\n",
    "\n",
    "    def __init__(self, n_examples):\n",
    "        digits, labels = zip(*[random_digits() for _ in range(n_examples)])\n",
    "        self.digits = np.asarray(digits, dtype=np.float64)\n",
    "        self.labels = np.asarray(labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        digit_with_channel = self.digits[idx][np.newaxis, :, :]\n",
    "        \n",
    "        return torch.from_numpy(digit_with_channel).float(), torch.from_numpy(np.array([self.labels[idx]]))\n",
    "\n",
    "# next(b for b in DataLoader(LcdDigits(128), batch_size=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "N_EPOCHS = 25\n",
    "BATCH_SIZE = 128\n",
    "LR = 0.005\n",
    "\n",
    "cnn = PixelCNN()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\n",
    "\n",
    "train_dataset = LcdDigits(BATCH_SIZE * 50)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    for i, (images, _) in enumerate(train_loader):\n",
    "        images = images # BATCH_SIZE x 1 x 13 x 8\n",
    "        pixelCNN_out = cnn(images) # BATCH_SIZE x 2 x 13 x 8\n",
    "        pixelCNN_target = torch.squeeze(images).long() # BATCH_SIZE x 13 x 8\n",
    "        optimizer.zero_grad()\n",
    "        loss = F.cross_entropy(input=pixelCNN_out, target=pixelCNN_target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print ('Epoch [%d/%d], Loss: %.4f' \n",
    "                   %(epoch+1, N_EPOCHS, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## input 이미지를 pixel-by-pixel 흝고 지나가면서 이미지 생성해보기\n",
    "<br>\n",
    "Sequentially generating new samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixelCNN로 새로운 샘플 만들기\n",
    "# 어떤 특정한 이미지를 pixelCNN의 input으로 줄 수도 있고 아니면 그냥 zeros를 넣어 줄 수도 있다.\n",
    "# pixelCNN은 input으로 주어진 이미지를 Masked Convolution으로 흝고 지나가면서 자신의 기억속에 존재하는, 가장 그럴듯한 픽셀 값을 예측해 낸다.\n",
    "def generate_samples(n_samples, starting_point=(0, 0), starting_image=None):\n",
    "    samples = torch.from_numpy(\n",
    "        starting_image if starting_image is not None else np.zeros((n_samples * n_samples, 1, IMAGE_WIDTH, IMAGE_HEIGHT))).float()\n",
    "\n",
    "    cnn.train(False)\n",
    "\n",
    "    # pixelCNN이 예측한 pixel-level distribution으로 부터 픽셀 값(0 또는 1)을 샘플링해서 이미지를 만들어 낸다.\n",
    "    for i in range(IMAGE_WIDTH):\n",
    "        for j in range(IMAGE_HEIGHT):\n",
    "            if i < starting_point[0] or (i == starting_point[0] and j < starting_point[1]):\n",
    "                continue\n",
    "            out = cnn(samples)\n",
    "            probs = F.softmax(out[:, :, i, j],1).data\n",
    "            samples[:, :, i, j] = torch.multinomial(probs, 1).float()\n",
    "    return samples.numpy()\n",
    "\n",
    "show_as_image(batch_images_to_one(generate_samples(n_samples=10)), figsize=(10, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지의 일부분을 input으로 주고, 나머지 부분을 완성하기\n",
    "<br>\n",
    "Or completing existing cropped image\n",
    "\n",
    " * $0, 8, 9$ and $2, 3, 7$ undistinguishable early one\n",
    " * Very small amount of noise (jitter) in samples\n",
    " * The last horizontal bar is hard to predict as it depends on the 1st horizontal bar\n",
    " * ($4, 9$) sometimes lead to incomplete or erroneous images because of the long term dependency between the upper and lower horizontal bars (could be improved by increasing the receptive field with more layers or \"à trous\" convolutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 10\n",
    "starting_point = (4, 3)\n",
    "\n",
    "mask = causal_mask(IMAGE_WIDTH, IMAGE_HEIGHT, starting_point)\n",
    "\n",
    "starting_images = digits_list = [random_digits(fixed_label=d)[0] for d in range(10)]\n",
    "batch_starting_images = np.expand_dims(np.stack([i * mask for i in starting_images] * n_images), axis=1)\n",
    "\n",
    "samples = generate_samples(n_images, starting_image=batch_starting_images, starting_point=starting_point)\n",
    "\n",
    "show_as_image(np.hstack([(1 + mask) * i for i in starting_images]), figsize=(10, 10))\n",
    "\n",
    "show_as_image(\n",
    "    batch_images_to_one((samples * (1 + mask))),\n",
    "    figsize=(10, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
